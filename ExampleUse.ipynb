{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c52b0c5",
   "metadata": {},
   "source": [
    "## Basic structure\n",
    "\n",
    "Various input files will be in disparate formats.  The intention here is to parse them into a standardized format.\n",
    "\n",
    "* baseMethod.py contains a dataclass called **genericLoggerFile** which is the template for standardizing data and metadata between file types.\n",
    "* All methods which parse a given file type, will "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6ea4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sourceFile': Field(name='sourceFile',type=<class 'str'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'timezone': Field(name='timezone',type=<class 'str'>,default='UTC',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'fileType': Field(name='fileType',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'frequency': Field(name='frequency',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'timestampName': Field(name='timestampName',type=<class 'str'>,default='TIMESTAMP',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'fileTimestamp': Field(name='fileTimestamp',type=<class 'str'>,default='%Y_%m_%d_%H%M',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'variableMap': Field(name='variableMap',type=<class 'dict'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function genericLoggerFile.<lambda> at 0x00000293774C6F20>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'DataFrame': Field(name='DataFrame',type=<class 'pandas.core.frame.DataFrame'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<class 'pandas.core.frame.DataFrame'>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'verbose': Field(name='verbose',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'binZip': Field(name='binZip',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'dropCols': Field(name='dropCols',type=<class 'list'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function genericLoggerFile.<lambda> at 0x00000293774C6FC0>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD)}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import baseMethods\n",
    "importlib.reload(baseMethods)\n",
    "\n",
    "# the .__dataclass_fields__ attribute prints the names of the fields in a dataclass and metadata like their default values\n",
    "baseMethods.genericLoggerFile(sourceFile='some/path/to/a/file').__dataclass_fields__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c945e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sourceFile': Field(name='sourceFile',type=<class 'str'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'timezone': Field(name='timezone',type=<class 'str'>,default='UTC',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'fileType': Field(name='fileType',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'frequency': Field(name='frequency',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'timestampName': Field(name='timestampName',type=<class 'str'>,default='TIMESTAMP',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'fileTimestamp': Field(name='fileTimestamp',type=<class 'str'>,default='%Y_%m_%d_%H%M',default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'variableMap': Field(name='variableMap',type=<class 'dict'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function asciiHeader.<lambda> at 0x00000293774E5300>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'DataFrame': Field(name='DataFrame',type=<class 'pandas.core.frame.DataFrame'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<class 'pandas.core.frame.DataFrame'>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'verbose': Field(name='verbose',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'binZip': Field(name='binZip',type=<class 'bool'>,default=False,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'dropCols': Field(name='dropCols',type=<class 'list'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function genericLoggerFile.<lambda> at 0x00000293774C6FC0>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'fileObject': Field(name='fileObject',type=<class 'object'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'header': Field(name='header',type=<class 'list'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function parseTOA5.<lambda> at 0x00000293774E5800>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'StationName': Field(name='StationName',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'LoggerModel': Field(name='LoggerModel',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'SerialNo': Field(name='SerialNo',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'program': Field(name='program',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'Table': Field(name='Table',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'byteMap': Field(name='byteMap',type=<class 'str'>,default=None,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=True,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'readData': Field(name='readData',type=<class 'bool'>,default=True,default_factory=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'Data': Field(name='Data',type=<class 'pandas.core.frame.DataFrame'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<class 'pandas.core.frame.DataFrame'>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD),\n",
       " 'calcStats': Field(name='calcStats',type=<class 'list'>,default=<dataclasses._MISSING_TYPE object at 0x0000029343E95280>,default_factory=<function parseTOA5.<lambda> at 0x00000293774E56C0>,init=True,repr=False,hash=None,compare=True,metadata=mappingproxy({}),kw_only=True,_field_type=_FIELD)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import parseCSI\n",
    "importlib.reload(parseCSI)\n",
    "\n",
    "\n",
    "file = r'example_data\\TOA5_BBS.FLUX_2023_08_01_1530.dat'\n",
    "\n",
    "parsedTOA5_example = parseCSI.parseTOA5(sourceFile=file)\n",
    "\n",
    "# The parseTOA5 dataclass has its onw fields plus all fields it inherits from the base dataclass (genericLoggerFile)\n",
    "parsedTOA5_example.__dataclass_fields__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d857457",
   "metadata": {},
   "source": [
    "### Looking inside a parsed input file\n",
    "\n",
    "The basic component of all processed logger files will include:\n",
    "\n",
    "* A pandas DataFrame with a datetime index containing all data which can be read form the raw data file\n",
    "    * timezone and frequency are metatadata provided as separate fields in the object\n",
    "* a variableMap \n",
    "    * A mapping of each column in the dataframe to with metadata including.  Some of these metadata can be automatically parsed from the files, depending on the file type.  Otherwise the can be provided by the user (see next second code example below)\n",
    "        * Original column name (spaces and special characters are replaced with _)\n",
    "        * Units & data type\n",
    "        * Sensor information \n",
    "        * Variable description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3036146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sourceFile: example_data\\TOA5_BBS.FLUX_2023_08_01_1530.dat\n",
      "timezone: UTC\n",
      "fileType: TOA5\n",
      "frequency: 0.1s\n",
      "timestampName: TIMESTAMP\n",
      "fileTimestamp: 2023_08_01_1530\n",
      "variableMap: {'RECORD': {'originalName': 'RECORD', 'ignore': False, 'instrument': None, 'unit': 'RN', 'dtype': '<i8', 'variableDescription': ''}, 'Ux': {'originalName': 'Ux', 'ignore': False, 'instrument': None, 'unit': 'm/s', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'Uy': {'originalName': 'Uy', 'ignore': False, 'instrument': None, 'unit': 'm/s', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'Uz': {'originalName': 'Uz', 'ignore': False, 'instrument': None, 'unit': 'm/s', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'Ts': {'originalName': 'Ts', 'ignore': False, 'instrument': None, 'unit': 'C', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'sonic_diag': {'originalName': 'sonic_diag', 'ignore': False, 'instrument': None, 'unit': 'arb', 'dtype': '<i8', 'variableDescription': 'Smp'}, 'CO2': {'originalName': 'CO2', 'ignore': False, 'instrument': None, 'unit': 'mg/m3', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'H2O': {'originalName': 'H2O', 'ignore': False, 'instrument': None, 'unit': 'mg/m3', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'press': {'originalName': 'press', 'ignore': False, 'instrument': None, 'unit': 'kPa', 'dtype': '<f8', 'variableDescription': 'Smp'}, 'irga_diag': {'originalName': 'irga_diag', 'ignore': False, 'instrument': None, 'unit': 'arb', 'dtype': '<i8', 'variableDescription': 'Smp'}}\n",
      "DataFrame:                           RECORD       Ux       Uy       Uz        Ts  \\\n",
      "TIMESTAMP                                                               \n",
      "2023-08-01 15:00:00.200  9455403  1.01600  1.21250  0.03475  26.94525   \n",
      "2023-08-01 15:00:00.300  9455404  1.08300  0.83575  0.37975  27.49509   \n",
      "2023-08-01 15:00:00.400  9455405  0.87350  1.01550  0.16575  27.23050   \n",
      "2023-08-01 15:00:00.500  9455406  0.80325  1.37725  0.09625  27.17688   \n",
      "2023-08-01 15:00:00.600  9455407  0.80075  1.31025  0.31650  27.25467   \n",
      "...                          ...      ...      ...      ...       ...   \n",
      "2023-08-01 15:29:59.700  9473398  0.74025 -0.05375  0.68875  28.10779   \n",
      "2023-08-01 15:29:59.800  9473399  0.38125 -0.43575  0.78025  28.10431   \n",
      "2023-08-01 15:29:59.900  9473400  0.08250 -0.34875  0.78875  28.06451   \n",
      "2023-08-01 15:30:00.000  9473401  0.36625 -0.32950  0.93600  28.76794   \n",
      "2023-08-01 15:30:00.100  9473402  0.54425 -0.35450  0.91325  29.35068   \n",
      "\n",
      "                         sonic_diag       CO2       H2O     press  irga_diag  \n",
      "TIMESTAMP                                                                     \n",
      "2023-08-01 15:00:00.200           0  723.3319  11.14806  102.1824        249  \n",
      "2023-08-01 15:00:00.300           1  723.9941  11.06973  102.1197        249  \n",
      "2023-08-01 15:00:00.400           2  721.9471  11.31256  102.1197        249  \n",
      "2023-08-01 15:00:00.500           3  721.6195  11.36601  102.1091        249  \n",
      "2023-08-01 15:00:00.600           4  721.8223  11.34038  102.1457        249  \n",
      "...                             ...       ...       ...       ...        ...  \n",
      "2023-08-01 15:29:59.700          11  720.5905  11.13130  102.1197        249  \n",
      "2023-08-01 15:29:59.800          12  720.3929  11.16998  102.0985        249  \n",
      "2023-08-01 15:29:59.900          13  720.3505  11.14703  102.1563        249  \n",
      "2023-08-01 15:30:00.000          14  719.5184  11.21988  102.1091        249  \n",
      "2023-08-01 15:30:00.100          15  715.4084  11.51652  102.0936        249  \n",
      "\n",
      "[18000 rows x 10 columns]\n",
      "verbose: False\n",
      "binZip: False\n",
      "dropCols: []\n",
      "fileObject: <_io.TextIOWrapper name='example_data\\\\TOA5_BBS.FLUX_2023_08_01_1530.dat' mode='r' encoding='cp1252'>\n",
      "header: {}\n",
      "StationName: BBS\n",
      "LoggerModel: CR1000\n",
      "SerialNo: 9816\n",
      "program: None\n",
      "Table: FLUX\n",
      "byteMap: None\n",
      "readData: True\n",
      "Data: Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "calcStats: []\n",
      "Type: TOA5\n"
     ]
    }
   ],
   "source": [
    "# the __dict__ attribute prints the names of the fields in a dataclass and their values\n",
    "for key,value in parsedTOA5_example.__dict__.items():\n",
    "    print(f'{key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d115492e",
   "metadata": {},
   "source": [
    "### Defining the variableMap\n",
    "\n",
    "* The variableMap is a dictionary with a set of fields which are a applied on a per-column (variable) basis.  They can be user defined, or automatically parsed from the file where possible, or if all else values, the will take the default values defined for _variableMap.\n",
    "\n",
    "* Say you want to overwrite the default metadata values for the \"sonic_diag\" column in example_data/TOA5_BBS.FLUX_2023_08_01_1530.dat because it is actually a counter variable that was misslabeled in the code.  We want to ignore the variable in further processing and add a note to explain why.  We can define variable map for sonic_diag while leaving all other information to be parsed automatically or set to the default.\n",
    "\n",
    "* The variableMap for a given input file type for a given site/logger can then be saved as a YAML file so the metadata are in an easy to read format.  We still need to put in some thought into handling time-dependent updates to the metadata.  Where the metatada are common between timestamps we can minimize storage by having one yaml file per time-block.  When the metadata update we need a new file (full or just partial documenting changes > I think full is more readable even if it takes more space).  We then need an time-dependent index of the metatada files so things can be matched up correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df672489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD:\n",
      "  originalName: RECORD\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: RN\n",
      "  dtype: <i8\n",
      "  variableDescription: ''\n",
      "Ux:\n",
      "  originalName: Ux\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: m/s\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "Uy:\n",
      "  originalName: Uy\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: m/s\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "Uz:\n",
      "  originalName: Uz\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: m/s\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "Ts:\n",
      "  originalName: Ts\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: C\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "sonic_diag:\n",
      "  originalName: sonic_diag\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: arb\n",
      "  dtype: <i8\n",
      "  variableDescription: Smp\n",
      "CO2:\n",
      "  originalName: CO2\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: mg/m3\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "H2O:\n",
      "  originalName: H2O\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: mg/m3\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "press:\n",
      "  originalName: press\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: kPa\n",
      "  dtype: <f8\n",
      "  variableDescription: Smp\n",
      "irga_diag:\n",
      "  originalName: irga_diag\n",
      "  ignore: false\n",
      "  instrument: null\n",
      "  unit: arb\n",
      "  dtype: <i8\n",
      "  variableDescription: Smp\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parsedTOA5_example_user_defined_varMap = parseCSI.parseTOA5(sourceFile=file,variableMap={'sonic_diag':\n",
    "                                                                                         {'variableDescription':'The diagnostic variable is corrupted and should be ignored',\n",
    "                                                                                          'ignore':True,\n",
    "                                                                                          'units':'unitless',}})\n",
    "\n",
    "import yaml\n",
    "print(yaml.safe_dump(parsedTOA5_example_user_defined_varMap.variableMap,sort_keys=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
